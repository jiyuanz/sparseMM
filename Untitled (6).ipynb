{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom IPython.display import display, HTML\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math\nimport copy\ndataset = pd.read_pickle('./train_dataset_perf.pkl')\n#dataset","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataset))\nx = dataset.filter(regex='x')\ny = dataset.filter(regex='y')\nfrom sklearn.model_selection import train_test_split\nprint(len(x))\nprint(len(y))\nyp = np.array(y)\nyy = np.zeros(shape=(100,5))\ntype(yp)\nfor i in range(len(y)):\n    print(yp[i][0])\n    yy[i, int(yp[i][0])] = 1","execution_count":27,"outputs":[{"output_type":"stream","text":"90\n90\n90\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n2.0\n2.0\n2.0\n0.0\n1.0\n0.0\n1.0\n1.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\n1.0\n0.0\n0.0\n1.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\n2.0\n1.0\n0.0\n0.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\n2.0\n0.0\n0.0\n0.0\n0.0\n1.0\n2.0\n2.0\n2.0\n2.0\n2.0\n0.0\n1.0\n0.0\n0.0\n0.0\n2.0\n2.0\n2.0\n2.0\n2.0\n2.0\n1.0\n0.0\n0.0\n1.0\n2.0\n2.0\n2.0\n2.0\n2.0\n2.0\n1.0\n1.0\n0.0\n1.0\n2.0\n2.0\n2.0\n2.0\n2.0\n2.0\n1.0\n1.0\n0.0\n1.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.shape)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=10, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=10, random_state=42)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint(x_val.shape)","execution_count":3,"outputs":[{"output_type":"stream","text":"(90, 100)\n(70, 100)\n(10, 100)\n(70, 1)\n(10, 1)\n(10, 100)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn    \nclass MLPModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(100, 5),\n            nn.ReLU(), \n            #nn.Linear(100, 1),\n            nn.Softmax(1)\n        )\n    def forward(self, input_tensor):\n        return self.model(input_tensor)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 100\nx_train = np.array(x_train)\nx_test = np.array(x_test)\nx_val = np.array(x_val)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\ny_val = np.array(y_val)\n\nx_dense_train = x_train\nx_dense_test = x_test\nx_dense_val = x_val\n#y_dense_train = y_train\n#y_dense_test = y_test\n#y_dense_val = y_val\ny_dense_train = yy[0:70]\ny_dense_test = yy[70:80]\ny_dense_val = yy[80:90]\nprint(y_dense_train.shape)\n\nx_dense_train = torch.from_numpy(x_dense_train).float()\ny_dense_train = torch.from_numpy(y_dense_train).float()\nx_dense_test = torch.from_numpy(x_dense_test).float()\ny_dense_test = torch.from_numpy(y_dense_test).float()\nx_dense_val = torch.from_numpy(x_dense_val).float()\ny_dense_val = torch.from_numpy(y_dense_val).float()","execution_count":36,"outputs":[{"output_type":"stream","text":"(70, 5)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MLPModel()\nbest_model = None\nlowest_val = float('inf')\n\nloss_fn = torch.nn.MSELoss(reduction='sum')\nlearning_rate = 1e-3\nepochs = 30000\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\nfor t in range(epochs):\n    y_pred = model(x_dense_train)\n    loss = loss_fn(y_pred, y_dense_train)\n\n    y_pred_val = model(x_dense_val)\n    val_loss = loss_fn(y_pred_val, y_dense_val)\n    if val_loss < lowest_val:\n        best_model = copy.deepcopy(model)\n        lowest_val = val_loss\n    if t%100 == 0:\n#         print(t, loss.item())\n        print(t, loss.item(), val_loss.item())\n    \n    optimizer.zero_grad()\n\n    # Backward pass: compute gradient of the loss with respect to model\n    # parameters\n    loss.backward()\n\n    # Calling the step function on an Optimizer makes an update to its\n    # parameters\n    optimizer.step()\n    \n    if t%100 == 0:\n#         print(t, loss.item())\n        nnn, index = torch.max(y_pred, 1)\n        print(t, index)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}