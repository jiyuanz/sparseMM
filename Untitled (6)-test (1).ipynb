{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom IPython.display import display, HTML\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math\nimport copy\ndataset = pd.read_pickle('./train_dataset_beta1to10_i100_j0.pkl')\n#dataset","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataset))\nx = dataset.filter(regex='x')\ny = dataset.filter(regex='y')\nfrom sklearn.model_selection import train_test_split\nprint(len(x))\nprint(len(y))\nyp = np.array(y)\nyy = np.zeros(shape=(100,5))\ntype(yp)\nfor i in range(len(y)):\n    print(yp[i][0])\n    yy[i, int(yp[i][0])] = 1","execution_count":2,"outputs":[{"output_type":"stream","text":"11\n11\n11\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.shape)\n#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=10, random_state=42)\n#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=10, random_state=42)\nx_train = x\nx_test = x\nx_val = x\ny_train = y\ny_test = y\ny_val = y\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint(x_val.shape)","execution_count":8,"outputs":[{"output_type":"stream","text":"(11, 100)\n(11, 100)\n(11, 100)\n(11, 5)\n(11, 5)\n(11, 100)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn    \nclass MLPModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(100, 5),\n            nn.ReLU(), \n            #nn.Linear(100, 1),\n            nn.Softmax(1)\n        )\n    def forward(self, input_tensor):\n        return self.model(input_tensor)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 100\nx_train = np.array(x_train)\nx_test = np.array(x_test)\nx_val = np.array(x_val)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\ny_val = np.array(y_val)\n\nx_dense_train = x_train\nx_dense_test = x_test\nx_dense_val = x_val\ny_dense_train = y_train\ny_dense_test = y_test\ny_dense_val = y_val\n#y_dense_train = yy[0:70]\n#y_dense_test = yy[70:80]\n#y_dense_val = yy[80:90]\nprint(y_dense_train.shape)\n\nx_dense_train = torch.from_numpy(x_dense_train).float()\ny_dense_train = torch.from_numpy(y_dense_train).float()\nx_dense_test = torch.from_numpy(x_dense_test).float()\ny_dense_test = torch.from_numpy(y_dense_test).float()\nx_dense_val = torch.from_numpy(x_dense_val).float()\ny_dense_val = torch.from_numpy(y_dense_val).float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MLPModel()\nbest_model = None\nlowest_val = float('inf')\n\nloss_fn = torch.nn.MSELoss(reduction='sum')\nlearning_rate = 1e-3\nepochs = 1000\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\nfor t in range(epochs):\n    y_pred = model(x_dense_train)\n    loss = loss_fn(y_pred, y_dense_train)\n\n    y_pred_val = model(x_dense_val)\n    val_loss = loss_fn(y_pred_val, y_dense_val)\n    if val_loss < lowest_val:\n        best_model = copy.deepcopy(model)\n        lowest_val = val_loss\n    if t%100 == 0:\n#         print(t, loss.item())\n        print(t, loss.item(), val_loss.item())\n    \n    optimizer.zero_grad()\n\n    # Backward pass: compute gradient of the loss with respect to model\n    # parameters\n    loss.backward()\n\n    # Calling the step function on an Optimizer makes an update to its\n    # parameters\n    optimizer.step()\n    \n    if t%100 == 0:\n#         print(t, loss.item())\n        nnn, index = torch.max(y_pred, 1)\n        nnn, index1 = torch.max(y_dense_train, 1)\n        print(t, index, index1)    \n        ","execution_count":16,"outputs":[{"output_type":"stream","text":"0 8.7161865234375 8.7161865234375\n0 tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n100 8.288359642028809 8.288359642028809\n100 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n200 7.866926670074463 7.866926670074463\n200 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n300 7.4280266761779785 7.4280266761779785\n300 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n400 6.9762396812438965 6.9762396812438965\n400 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n500 6.517311096191406 6.517311096191406\n500 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n600 6.057114124298096 6.057114124298096\n600 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n700 5.602084636688232 5.602084636688232\n700 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n800 5.158168792724609 5.158168792724609\n800 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n900 4.730750560760498 4.730750560760498\n900 tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}